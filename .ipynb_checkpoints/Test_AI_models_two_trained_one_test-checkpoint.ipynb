{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a17b8d-a220-42a7-8eb5-64bb36459ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.base import clone\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c252a6-9935-4b9c-8223-1d3b5be030e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    df_clean = df.iloc[1:].copy()\n",
    "    df_clean.columns = df.iloc[0]  # First row as column names\n",
    "\n",
    "    labels = df_clean.iloc[-1]\n",
    "    features = df_clean.iloc[:-1]\n",
    "\n",
    "    labeled_idx = labels.dropna().index\n",
    "    X = features[labeled_idx].astype(float).T\n",
    "    y = labels[labeled_idx].astype(int)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983cbd63-e8df-4203-ae57-3f95330f9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dataset_weights(datasets):\n",
    "    dataset_sizes = []\n",
    "    for df in datasets:\n",
    "        _, y = prepare_data(df)\n",
    "        dataset_sizes.append(len(y))\n",
    "\n",
    "    total_size = sum(dataset_sizes)\n",
    "    weights = [total_size / size for size in dataset_sizes]  # inverse proportional\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a5187-5c20-4fc8-8e45-970ad1a8a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_with_row_labels(filepath):\n",
    "    if filepath.endswith('.csv'):\n",
    "        df = pd.read_csv(filepath, header=None)\n",
    "    else:\n",
    "        df = pd.read_excel(filepath, header=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e273ff70-e486-41bf-b56c-2dfb7e1c116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weight_dict(y):\n",
    "    classes = np.unique(y)\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y)\n",
    "    return dict(zip(classes, class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f34e55-40c9-4f93-8961-b1495073e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lda', LDA(solver='lsqr', shrinkage='auto'))\n",
    "])\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=0))\n",
    "])\n",
    "xgb_params = {\n",
    "    'xgb__n_estimators': [50, 100],\n",
    "    'xgb__max_depth': [3, 4],\n",
    "    'xgb__learning_rate': [0.05, 0.1]\n",
    "}\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, max_depth=None, random_state=0))\n",
    "])\n",
    "\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(kernel='rbf', random_state=0))\n",
    "])\n",
    "svm_params = {\n",
    "    'svc__C': [0.1, 1.0, 10],\n",
    "    'svc__gamma': ['scale', 0.01, 0.001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917c4b0-0ec3-4e91-bfa6-90d29b9a8080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix_with_totals(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_df = pd.DataFrame(cm, index=[f\"{l}_true\" for l in labels],\n",
    "                         columns=[f\"{l}_pred\" for l in labels])\n",
    "    \n",
    "    cm_df[\"Total\"] = cm_df.sum(axis=1)\n",
    "    total_row = cm_df.sum(axis=0)\n",
    "    total_row.name = \"Total\"\n",
    "    cm_df = pd.concat([cm_df, pd.DataFrame([total_row])])\n",
    "\n",
    "    annot = cm_df.astype(str)\n",
    "    for i in range(len(labels)):\n",
    "        row_sum = cm_df.iloc[i, :-1].sum()\n",
    "        for j in range(len(labels)):\n",
    "            count = cm_df.iloc[i, j]\n",
    "            pct = (count / row_sum * 100) if row_sum > 0 else 0\n",
    "            annot.iloc[i, j] = f\"{count} ({pct:.0f}%)\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.axis(\"off\")\n",
    "    table = ax.table(cellText=annot.values,\n",
    "                     rowLabels=annot.index,\n",
    "                     colLabels=annot.columns,\n",
    "                     loc=\"center\",\n",
    "                     cellLoc=\"center\")\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.2)\n",
    "    plt.title(\"Confusion Matrix with Totals\", pad=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aebfe0-ff18-4bf2-a577-3831a8c6dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2014 = load_dataset_with_row_labels(r\"C:\\Users\\Paolo\\OneDrive\\Desktop\\Thesis\\Mycos_old_data (1)\\width_extraction\\result\\merged_14_20_with_avarage.xlsx\")\n",
    "ds2005 = load_dataset_with_row_labels(r\"C:\\Users\\Paolo\\OneDrive\\Desktop\\Thesis\\Mycos_old_data (1)\\width_extraction\\result\\merged_widths_200_Ok_SAM_2005.csv\")\n",
    "ds2025 = load_dataset_with_row_labels(r\"C:\\Users\\Paolo\\OneDrive\\Desktop\\Thesis\\Mycos_old_data (1)\\Mycos_old_data\\20250613_Cuc_Mycos_RGB\\ready_for_testing_2025.xlsx\")\n",
    "\n",
    "datasets = [ds2014, ds2005, ds2025]\n",
    "names = ['ds2014', 'ds2005', 'ds2025']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf87de3-e963-4c44-aede-9e337c21bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_combinations(datasets, names):\n",
    "    combinations = [\n",
    "        ([0, 1], 2),\n",
    "        ([0, 2], 1),\n",
    "        ([1, 2], 0)\n",
    "    ]\n",
    "\n",
    "    for train_idxs, test_idx in combinations:\n",
    "        train_name = f\"{names[train_idxs[0]]} + {names[train_idxs[1]]}\"\n",
    "        test_name = names[test_idx]\n",
    "\n",
    "        # Prepare train data\n",
    "        X_train_list, y_train_list = [], []\n",
    "        for idx in train_idxs:\n",
    "            X, y = prepare_data(datasets[idx])\n",
    "            X_train_list.append(X)\n",
    "            y_train_list.append(y)\n",
    "\n",
    "        X_train = pd.concat(X_train_list).reset_index(drop=True)\n",
    "        y_train = pd.concat(y_train_list).reset_index(drop=True)\n",
    "\n",
    "        # Prepare test data\n",
    "        X_test, y_test = prepare_data(datasets[test_idx])\n",
    "\n",
    "        # Dynamic CV\n",
    "        n_splits = 5 if len(y_train) >= 10 else len(y_train)\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "        # Class weights\n",
    "        class_weight_dict = get_class_weight_dict(y_train)\n",
    "\n",
    "        # Models\n",
    "        model_defs = {\n",
    "            \"LDA\": lda_pipeline,\n",
    "            \"XGBoost\": GridSearchCV(xgb_pipeline, xgb_params, cv=cv, scoring='accuracy', n_jobs=-1),\n",
    "            \"RandomForest\": rf_pipeline,\n",
    "            \"SVM\": GridSearchCV(svm_pipeline, svm_params, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "        }\n",
    "\n",
    "        for model_name, model in model_defs.items():\n",
    "            print(f\"\\n▶️ Model: {model_name} | Train: {train_name} | Test: {test_name}\")\n",
    "\n",
    "            model = clone(model)\n",
    "\n",
    "            # Apply class_weight to supported models\n",
    "            if model_name == \"RandomForest\":\n",
    "                model.set_params(rf__class_weight=class_weight_dict)\n",
    "            elif model_name == \"SVM\":\n",
    "                model.estimator.set_params(svc__class_weight=class_weight_dict)\n",
    "\n",
    "            # Handle XGBoost imbalance\n",
    "            if model_name == \"XGBoost\":\n",
    "                n_pos = sum(y_train == 1)\n",
    "                n_neg = sum(y_train == 0)\n",
    "                if n_pos > 0:\n",
    "                    model.estimator.set_params(xgb__scale_pos_weight=n_neg / n_pos)\n",
    "\n",
    "            # CV fit\n",
    "            cross_val_score(model, X_train, y_train, cv=cv)\n",
    "\n",
    "            # Final train\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predictions\n",
    "            predictions = model.predict(X_test)\n",
    "            acc = accuracy_score(y_test, predictions)\n",
    "            print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "            plot_confusion_matrix_with_totals(y_test, predictions, labels=model.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adacbb2-7ff3-41f5-8f1f-52ab005877b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_all_combinations(datasets, names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
